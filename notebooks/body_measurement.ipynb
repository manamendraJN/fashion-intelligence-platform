{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbo8/EOVGeQ3LlCY8nNTdI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manamendraJN/fashion-intelligence-platform/blob/feature%2Fbody-measurement-and-sizing/notebooks/body_measurement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1 - Setup and Environment Configuration"
      ],
      "metadata": {
        "id": "2tUSXsm4wbxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_-jr6zxvgaZ",
        "outputId": "7cc0ae9f-e2c6-4250-d0bc-d3597a9e7009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student: manamendraJN | Date: 2025-12-11 04:53:48\n",
            "Python:  3.12.12\n",
            "âœ… PyTorch 2.9.0+cu126 | Device: cuda\n",
            "âœ… GPU:  Tesla T4 (15.8 GB)\n",
            "ðŸŽ² Running without fixed seeds (non-deterministic mode)\n"
          ]
        }
      ],
      "source": [
        "# PURPOSE: Install required packages, import libraries, and configure the environment\n",
        "# WHY: Sets up all dependencies needed for deep learning model training\n",
        "\n",
        "import sys\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Print session information for tracking\n",
        "print(f\"Student: manamendraJN | Date: {datetime.now(timezone. utc).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Python:  {sys.version. split()[0]}\")\n",
        "\n",
        "# Install required packages silently (-q flag)\n",
        "# timm: Pre-trained vision models library\n",
        "# albumentations: Advanced image augmentation library\n",
        "! pip install -q timm albumentations\n",
        "\n",
        "# Core deep learning imports\n",
        "import torch\n",
        "import torch.nn as nn  # Neural network layers\n",
        "import torch.optim as optim  # Optimizers (AdamW)\n",
        "from torch.utils.data import Dataset, DataLoader  # Data loading utilities\n",
        "import timm  # Pre-trained models (EfficientNet, ResNet, MobileNet)\n",
        "\n",
        "# Data processing imports\n",
        "import numpy as np  # Numerical operations\n",
        "import pandas as pd  # CSV/dataframe handling\n",
        "import cv2  # Image loading\n",
        "from pathlib import Path  # File path operations\n",
        "import json  # Save/load configuration files\n",
        "\n",
        "# Image augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Utilities\n",
        "from tqdm. auto import tqdm  # Progress bars\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "import seaborn as sns  # Statistical visualizations\n",
        "from sklearn.metrics import r2_score  # RÂ² metric calculation\n",
        "\n",
        "# Configure plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "# WHY: GPU is 10-100x faster for deep learning\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Print environment information\n",
        "print(f\"âœ… PyTorch {torch.__version__} | Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU:  {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB)\")\n",
        "print(\"ðŸŽ² Running without fixed seeds (non-deterministic mode)\")\n",
        "# NOTE: No random seeds = different results each run (but more realistic generalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2 - Google Drive Integration and Directory Setup"
      ],
      "metadata": {
        "id": "hO2IWNtTxUKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE: Mount Google Drive and create project directory structure\n",
        "# WHY:  Persist data/models across Colab sessions and organize outputs\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (force_remount=True ensures clean mount)\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create project directory in Colab's temporary storage\n",
        "# WHY: Faster read/write than Drive, we'll copy results back later\n",
        "PROJECT_DIR = Path('/content/body_measurement_research')\n",
        "PROJECT_DIR.mkdir(exist_ok=True)  # exist_ok=True prevents error if already exists\n",
        "\n",
        "# Change working directory to project folder\n",
        "import os\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "# Create subdirectories for organized storage\n",
        "# models:  Saved model weights (. pth files)\n",
        "# results: JSON files with metrics and statistics\n",
        "# checkpoints: Intermediate training checkpoints (not used currently)\n",
        "# visualizations: Generated plots and charts\n",
        "for d in ['models', 'results', 'checkpoints', 'visualizations']:\n",
        "    (PROJECT_DIR / d).mkdir(exist_ok=True)\n",
        "\n",
        "# Point to dataset location in Google Drive\n",
        "# WHY: Data stays in Drive (permanent), we load from there\n",
        "DRIVE_DATA_PATH = Path('/content/drive/MyDrive/body_measurement_data/train')\n",
        "print(f\"âœ… Setup complete | Data:  {DRIVE_DATA_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqmLDvIaxVQZ",
        "outputId": "5c64d181-4ddf-4702-fc85-0689d6573dfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Setup complete | Data:  /content/drive/MyDrive/body_measurement_data/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3 - Load Dataset from CSV Files\n"
      ],
      "metadata": {
        "id": "3ispu_1Nxwvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE: Load and merge three CSV files containing photos, measurements, and metadata\n",
        "# WHY: We need to combine subject IDs with their photos and body measurements\n",
        "\n",
        "# Load three separate CSV files\n",
        "# 1. subject_to_photo_map. csv: Maps subject_id â†’ photo_id\n",
        "# 2. measurements. csv: Contains 14 body measurements per subject_id\n",
        "# 3. hwg_metadata.csv: Contains height, weight, gender per subject_id\n",
        "photos_df = pd.read_csv(DRIVE_DATA_PATH / 'subject_to_photo_map.csv')\n",
        "measurements_df = pd.read_csv(DRIVE_DATA_PATH / 'measurements.csv')\n",
        "metadata_df = pd.read_csv(DRIVE_DATA_PATH / 'hwg_metadata.csv')\n",
        "\n",
        "# Merge dataframes on 'subject_id' column\n",
        "# WHY: We need photo_id, measurements, and metadata in one table\n",
        "# how='inner':  Only keep subjects that exist in ALL three files\n",
        "data = photos_df.merge(measurements_df, on='subject_id', how='inner')\n",
        "data = data.merge(metadata_df, on='subject_id', how='inner')\n",
        "\n",
        "# Extract measurement column names (exclude non-measurement columns)\n",
        "# WHY: We need to know which columns are our prediction targets\n",
        "exclude_cols = ['subject_id', 'Unnamed: 0']  # Remove ID columns\n",
        "MEASUREMENT_COLUMNS = [col for col in measurements_df.columns if col not in exclude_cols]\n",
        "# Result: 14 measurements (chest, waist, hip, shoulder, arm, leg, etc.)\n",
        "\n",
        "print(f\"âœ… Loaded {len(data)} samples | {len(MEASUREMENT_COLUMNS)} measurements\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brr1M0pJxxf_",
        "outputId": "1228d34c-a8a5-4b42-d3aa-ec3ffe3c49d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 6134 samples | 14 measurements\n"
          ]
        }
      ]
    }
  ]
}